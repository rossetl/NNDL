{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder-Rosset-Lorenzo",
      "provenance": [],
      "authorship_tag": "ABX9TyO8S4hfIfIPxii8d+XZGoJr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7uNBdlA6MF_"
      },
      "outputs": [],
      "source": [
        "%pip install optuna\n",
        "%pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import I\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, Subset, random_split\n",
        "from sklearn.model_selection import KFold\n",
        "import pytorch_lightning as pl\n",
        "from optuna.integration import PyTorchLightningPruningCallback"
      ],
      "metadata": {
        "id": "EEcgzD0q-Jui"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCHSIZE = 20\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "NUM_CLASSES = 10\n",
        "print(f'Training device:', DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z9sFBlR6fCY",
        "outputId": "24ab2853-dc0a-44dd-c417-ab142d8495be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, encoded_space_dim=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder_cnn = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=0, stride=2),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        self.flatten = nn.Flatten(start_dim=1)\n",
        "\n",
        "        self.encoder_fc = nn.Sequential(\n",
        "            nn.Linear(in_features=32*3*3, out_features=64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(in_features=64, out_features=encoded_space_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder_cnn(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.encoder_fc(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, encoded_space_dim=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.decoder_fc = nn.Sequential(\n",
        "            nn.Linear(in_features=encoded_space_dim, out_features=64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(in_features=64, out_features=32*3*3),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
        "        \n",
        "        self.decoder_conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, padding=0, output_padding=0, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, padding=1, output_padding=1, stride=2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=3, padding=1, output_padding=1, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.decoder_fc(x)\n",
        "        x = self.unflatten(x)\n",
        "        x = self.decoder_conv(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "OVbmD7OTa_Gq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "class FashionMNISTDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, batch_size: int):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None) -> None:\n",
        "        self.mnist_test = torchvision.datasets.FashionMNIST('classifier_data', train=False, download=True, transform=transforms.ToTensor())\n",
        "        mnist_full = torchvision.datasets.FashionMNIST('classifier_data', train=True, download=True, transform=transforms.ToTensor())\n",
        "        self.mnist_train, self.mnist_val = random_split(mnist_full, [10000, 1000])\n",
        "\n",
        "    def train_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(self.mnist_train, batch_size=self.batch_size, shuffle=True)\n",
        "    \n",
        "    def val_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(self.mnist_val, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(self.test_val, batch_size=self.batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "XQn9K5N8-ntn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightningNet(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, encoded_space_dim):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(encoded_space_dim)\n",
        "        self.decoder = Decoder(encoded_space_dim)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        data, label = batch\n",
        "        output = self(data)\n",
        "        return self.loss_fn(output, data)\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        data, label = batch\n",
        "        output = self(data)\n",
        "        loss = self.loss_fn(output, data)\n",
        "        self.log('val_loss', loss)\n",
        "        self.log('hp_metric', loss, on_step=False, on_epoch=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.model.parameters())"
      ],
      "metadata": {
        "id": "75368Zqe6zFC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(\n",
        "    logger=True,\n",
        "    limit_val_batches=0.1,\n",
        "    checkpoint_callback=False,\n",
        "    max_epochs=5,\n",
        "    gpus=1 if torch.cuda.is_available() else None,\n",
        "    callbacks=[]\n",
        ")\n",
        "\n",
        "model = LightningNet(2)\n",
        "datamodule = FashionMNISTDataModule(batch_size=BATCHSIZE)\n",
        "\n",
        "trainer.fit(model, datamodule=datamodule)"
      ],
      "metadata": {
        "id": "LOK5ImVRy-n0",
        "outputId": "9d730e9c-ec1e-47b8-8c87-7dda44bf6616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:148: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
            "  f\"Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will \"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-fe12695434ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdatamodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFashionMNISTDataModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCHSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatamodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mtrain_dataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         self._call_and_handle_interrupt(\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m         )\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \"\"\"\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;31m# TODO: ckpt_path only in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach_model_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach_model_logging_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py\u001b[0m in \u001b[0;36m_attach_model_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpushed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mend\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensuring\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \"\"\"\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mmodel_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"configure_callbacks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mcall_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m         \u001b[0mpl_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m             \u001b[0mprev_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1487\u001b[0m             \u001b[0mpl_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LightningNet' object has no attribute '_current_fx_name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9h1xacrC0wWr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}